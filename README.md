# Driftline â€“ Global SAR Drift Forecasting SaaS Platform

![Driftline Logo](https://via.placeholder.com/150x50?text=Driftline)

**Driftline** is a global, self-serve Search and Rescue (SAR) drift forecasting SaaS platform that provides web-based and API-driven probabilistic drift forecasts using environmental forcing data and OpenDrift Lagrangian particle modeling.

## ğŸŒŠ Overview

Driftline answers the critical question:

> *"Given the last known position and time of an abandoned vessel or person, where is the most likely position now, and where should search resources be deployed?"*

## ğŸ—ï¸ Architecture

The platform is built with a modern microservices architecture:

- **Frontend**: React + TypeScript with MapLibre GL for interactive mapping
- **API Server**: Go (Gin framework) for authentication, missions, and billing
- **Drift Worker**: Python + OpenDrift for Lagrangian particle simulations
- **Data Service**: Go for managing environmental forcing data
- **Results Processor**: Python for generating derived products and reports
- **Infrastructure**: Docker + Docker Compose, PostgreSQL, Redis, MinIO
- **Monitoring**: Prometheus + Grafana

## ğŸ“‹ Prerequisites

- Docker 24+ and Docker Compose 2.20+
- Go 1.21+ (for local development)
- Node.js 20+ (for frontend development)
- Python 3.11+ (for worker development)
- 8GB+ RAM recommended
- 20GB+ disk space

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/eysteinn/driftline.git
cd driftline
```

### 2. Set Up Environment

```bash
cp .env.example .env
# Edit .env with your configuration
```

### 3. Start Development Environment

```bash
docker-compose -f docker-compose.dev.yml up --build
```

This will start all services:

- **Frontend**: http://localhost:3000
- **API Server**: http://localhost:8000
- **MinIO Console**: http://localhost:9001 (admin/minioadmin)
- **Grafana**: http://localhost:3001 (admin/admin)
- **Prometheus**: http://localhost:9090

### 4. Initialize the Database

The database schema is automatically initialized on first startup via the SQL scripts in `sql/init/`.

### 5. Access the Application

Open your browser and navigate to:
- **Web UI**: http://localhost:3000
- **API Health Check**: http://localhost:8000/health
- **API Documentation**: http://localhost:8000/docs (when implemented)

## ğŸ“ Project Structure

```
driftline/
â”œâ”€â”€ frontend/                  # React + TypeScript frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/       # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ pages/           # Page components
â”‚   â”‚   â”œâ”€â”€ services/        # API client
â”‚   â”‚   â”œâ”€â”€ stores/          # State management (Zustand)
â”‚   â”‚   â””â”€â”€ types/           # TypeScript types
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ api/                 # Go API server
â”‚   â”‚   â”œâ”€â”€ cmd/
â”‚   â”‚   â”‚   â””â”€â”€ api-gateway/ # Main entry point
â”‚   â”‚   â”œâ”€â”€ internal/
â”‚   â”‚   â”‚   â”œâ”€â”€ auth/        # Authentication logic
â”‚   â”‚   â”‚   â”œâ”€â”€ missions/    # Mission management
â”‚   â”‚   â”‚   â”œâ”€â”€ billing/     # Billing and subscriptions
â”‚   â”‚   â”‚   â””â”€â”€ database/    # Database layer
â”‚   â”‚   â”œâ”€â”€ pkg/
â”‚   â”‚   â”‚   â””â”€â”€ models/      # Data models
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ go.mod
â”‚   â”œâ”€â”€ drift-worker/        # Python + OpenDrift worker
â”‚   â”‚   â”œâ”€â”€ worker.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ data-service/        # Go data service
â”‚   â”‚   â”œâ”€â”€ cmd/
â”‚   â”‚   â”œâ”€â”€ internal/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ go.mod
â”‚   â””â”€â”€ results-processor/   # Python results processor
â”‚       â”œâ”€â”€ processor.py
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â””â”€â”€ Dockerfile
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ init/                # Database initialization scripts
â”‚       â””â”€â”€ 01_schema.sql
â”œâ”€â”€ nginx/                   # Nginx configurations
â”‚   â”œâ”€â”€ nginx.dev.conf
â”‚   â””â”€â”€ nginx.prod.conf
â”œâ”€â”€ monitoring/              # Monitoring configuration
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â””â”€â”€ grafana/
â”‚       â””â”€â”€ dashboards/
â”œâ”€â”€ docker-compose.dev.yml   # Development environment
â”œâ”€â”€ docker-compose.prod.yml  # Production environment
â”œâ”€â”€ .env.example            # Environment variables template
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ› ï¸ Development

### Frontend Development

```bash
cd frontend
npm install
npm run dev
```

### API Server Development

```bash
cd services/api
go mod download
go run cmd/api-gateway/main.go
```

### Worker Development

```bash
cd services/drift-worker
pip install -r requirements.txt
python worker.py
```

## ğŸ§ª Testing

### Run Frontend Tests

```bash
cd frontend
npm test
```

### Run API Tests

```bash
cd services/api
go test ./...
```

### Run Python Tests

```bash
cd services/drift-worker
pytest
```

## ğŸ“¦ Building for Production

### Build All Images

```bash
docker-compose -f docker-compose.prod.yml build
```

### Deploy to Production

```bash
# Set production environment variables in .env
docker-compose -f docker-compose.prod.yml up -d
```

## ğŸ”§ Configuration

### Environment Variables

See `.env.example` for all available configuration options.

Key variables:

- `DATABASE_URL`: PostgreSQL connection string
- `REDIS_URL`: Redis connection string
- `JWT_SECRET_KEY`: Secret key for JWT token signing
- `S3_ENDPOINT`: MinIO/S3 endpoint
- `STRIPE_API_KEY`: Stripe API key for billing (optional)

### Database Migrations

Database schema is managed via SQL scripts in `sql/init/`. For schema changes:

1. Add new migration scripts with sequential numbering
2. Restart the database service to apply changes

## ğŸ“Š Monitoring

Access monitoring dashboards:

- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3001 (default: admin/admin)

Available metrics:

- API request rates and latencies
- Mission creation and completion rates
- Job queue depth
- Worker utilization
- Database performance
- Storage usage

## ğŸ”’ Security

- All passwords should be changed from defaults in production
- Use strong, randomly generated secrets for `JWT_SECRET_KEY`
- Enable SSL/TLS in production (configure certificates in nginx)
- Implement rate limiting (configured in nginx)
- Regularly update dependencies

## ğŸ“š API Documentation

API endpoints are organized under `/v1/`:

### Authentication
- `POST /v1/auth/register` - Register new user
- `POST /v1/auth/login` - Login and get JWT token
- `POST /v1/auth/refresh` - Refresh access token

### Missions
- `POST /v1/missions` - Create new mission
- `GET /v1/missions` - List user missions
- `GET /v1/missions/:id` - Get mission details
- `DELETE /v1/missions/:id` - Delete mission
- `GET /v1/missions/:id/status` - Get job status
- `GET /v1/missions/:id/results` - Download results

### User Management
- `GET /v1/users/me` - Get current user
- `PATCH /v1/users/me` - Update user profile

### Billing
- `GET /v1/billing/usage` - Get usage statistics
- `GET /v1/billing/invoices` - List invoices

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is proprietary software. All rights reserved.

## ğŸ“ Support

For support, email support@driftline.io or open an issue in the repository.

## ğŸ—ºï¸ Roadmap

### Phase 1: MVP (Current)
- âœ… Core services setup
- â³ Basic web UI
- â³ OpenDrift integration
- â³ Mission management
- â³ Results visualization

### Phase 2: Beta
- â³ Billing integration (Stripe)
- â³ PDF report generation
- â³ Real-time WebSocket updates
- â³ Data caching service
- â³ Monitoring and alerting

### Phase 3: Production
- â³ Multi-region deployment
- â³ Advanced visualizations
- â³ Mobile-responsive UI
- â³ API rate limiting
- â³ Documentation portal

### Phase 4: Scale
- â³ Kubernetes migration
- â³ Auto-scaling
- â³ Machine learning enhancements
- â³ AIS data integration
- â³ Enterprise SSO

## ğŸ™ Acknowledgments

- OpenDrift - Open source Lagrangian particle tracking framework
- Copernicus Marine Service - Ocean data
- NOAA - Weather and wave data
- All open source contributors

---

**Built with â¤ï¸ for Search and Rescue operations worldwide**
